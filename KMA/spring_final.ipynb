{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e910051-2cb5-4198-8773-f34a32d6256d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from statsmodels.robust import mad\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc('font', family='NanumGothic') # 한글 표현 for Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 마이너스 부호 표현\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "class GroupTimeSeriesSplit(_BaseKFold):\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_size=None\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_size = max_train_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "        group_test_size = n_groups // n_folds\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "            for train_group_idx in unique_groups[:group_test_start]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "            train_end = train_array.size\n",
    "            if self.max_train_size and self.max_train_size < train_end:\n",
    "                train_array = train_array[train_end -\n",
    "                                          self.max_train_size:train_end]\n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86fa9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웨이블릿 변환 코드\n",
    "def WT(df, col, wavelet='db5', thresh=0.63):\n",
    "    signal = df[col].values\n",
    "    thresh = thresh*np.nanmax(signal)\n",
    "    coeff = pywt.wavedec(signal, wavelet, mode=\"per\" )\n",
    "    coeff[1:] = (pywt.threshold(i, value=thresh, mode=\"soft\" ) for i in coeff[1:])\n",
    "    reconstructed_signal = pywt.waverec(coeff, wavelet, mode=\"per\" )\n",
    "    return reconstructed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e731640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feature(df):\n",
    "    \n",
    "    # abnormal value adjustment\n",
    "    df['solar_amt'] = df['solar_amt'].apply(lambda x: 0 if x<0 else x)\n",
    "    df['solar_time'] = df['solar_time'].apply(lambda x: 0 if x<0 else x)\n",
    "    df['rain'] = df['rain'].apply(lambda x: 0 if x<0 else x)\n",
    "    df['tf_rain'] = df['tf_rain'].apply(lambda x: 0 if x<0 else x/60)\n",
    "    df['humid'] = df['humid'].apply(lambda x: 0 if x<0 else x/100)\n",
    "    df['snow'] = df['snow'].apply(lambda x: 0 if x<=-99 else x)\n",
    "    \n",
    "    # preprocessing\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24.0)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24.0)\n",
    "    \n",
    "    # difference\n",
    "    df['temp_diff'] = df['temp'] - df['dp_temp']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cb1bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_group(group, wthr):\n",
    "    group = group.reset_index(drop=True)\n",
    "    group[f'{wthr}_diff'] = group[wthr].diff()\n",
    "    group[f'after_{wthr}'] = 0\n",
    "    idx_list = group[group[f'{wthr}_diff']>0].index\n",
    "    for idx in idx_list:\n",
    "        for i in range(24):\n",
    "            if idx+i < len(group):\n",
    "                group.loc[idx+i, 'after_'+wthr] = i+1\n",
    "                \n",
    "    return group\n",
    "\n",
    "# 웨이블릿 변환한 dataframe 반환\n",
    "def gen_wv_df(original_df: pd.DataFrame, t: str):\n",
    "    # t : 'train' or 'test'\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    wv_df = pd.DataFrame()\n",
    "    if t == 'train':\n",
    "        year_ls = ['A','B','C','D','E']\n",
    "        area_ls = range(1,11)\n",
    "    elif t == 'test':\n",
    "        year_ls = ['F']\n",
    "        area_ls = range(1,4)\n",
    "    \n",
    "    # 이슬점과 습도에 대한 웨이블릿 변환 후 dataframe 반환\n",
    "    for j in year_ls:\n",
    "        for i in area_ls:\n",
    "            temp = df[(df.area==i) & (df.year==j)]\n",
    "\n",
    "            temp_1 = WT(temp, 'dp_temp', wavelet='db5', thresh=0.85)\n",
    "            temp_2 = WT(temp, 'humid', wavelet='db5', thresh=0.85)\n",
    "\n",
    "            temp_1 = pd.Series(temp_1, index=temp.index, name='dp_temp')\n",
    "            temp_2 = pd.Series(temp_2, index=temp.index, name='humid')\n",
    "\n",
    "            temp_df = pd.concat([temp_1, temp_2, temp.drop(['dp_temp','humid'], axis=1)], axis=1)\n",
    "            wv_df = pd.concat([wv_df, temp_df], axis=0)\n",
    "    \n",
    "    return wv_df\n",
    "\n",
    "def add_lag(original_df: pd.DataFrame, lag_cols: list, lags: list, t: str):\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # 웨이블릿 변환한 데이터프레임 반환\n",
    "    df = gen_wv_df(df, t)\n",
    "    \n",
    "    for col in lag_cols:\n",
    "        for i in lags:\n",
    "            df[f'{col}_lag_{i}'] = df.groupby(['area'])[col].shift(periods=i)\n",
    "            \n",
    "    #cumulative\n",
    "    df['rain_mask'] = (df['tf_rain'] != 0).astype(int)\n",
    "    df['rain_group'] = (df['rain_mask'].diff() < 0).astype(int).cumsum()\n",
    "    df['rain_count'] = df.groupby(['area', 'rain_group'])['rain_mask'].apply(lambda x: x.cumsum() * x).reset_index(drop=True)\n",
    "    df.drop(['rain_mask', 'rain_group'], axis=1, inplace=True)\n",
    "    \n",
    "    df['solar_amt_sum'] = df.groupby('area')['solar_amt'].rolling(window=3).sum().reset_index(drop=True)\n",
    "    \n",
    "    df = df.groupby('area').apply(process_group, wthr=\"snow\")\n",
    "    df.drop('snow_diff', axis=1, inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    df = df.groupby('area').apply(process_group, wthr=\"rain\")\n",
    "    df.drop('rain_diff', axis=1, inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # interaction 추가한 항\n",
    "    df['temp_dp_temp'] = df[['temp', 'dp_temp']].product(axis=1)\n",
    "    df['temp_humid'] = df[['temp','humid']].product(axis=1)\n",
    "    df['temp_wind'] = df[['temp','wind']].product(axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38d0882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weather_df(original_df:pd.DataFrame, surface: pd.DataFrame, weather:str, adj:bool, fog_split:dict):\n",
    "    # adj: snow adjustment 여부 \n",
    "    # fog split: fog 변수 분할 방법\n",
    "    \n",
    "    df = original_df.copy()\n",
    "    if adj == True:\n",
    "        # temp에 대한 처리\n",
    "        idx = df[df.snow!=0].index\n",
    "        temp = df.loc[idx,'snow'].apply(lambda x: 1+abs(x)*8)\n",
    "        df.loc[idx,'temp'] = df.loc[idx,'temp']/(temp)\n",
    "        \n",
    "        # solar_amt에 대한 처리\n",
    "        idx_2 = df[(df.snow>=0.1)&(df.solar_amt>0)].index\n",
    "        df.loc[idx_2, 'solar_amt'] = (df.loc[idx_2,'solar_amt']) / (df.loc[idx_2,'snow'].apply(lambda x: 1+abs(x)))\n",
    "        \n",
    "        # 주기성 제거\n",
    "        df.loc[idx, ['hour_sin','hour_cos']] = 0\n",
    "        \n",
    "    if weather == 'spring':\n",
    "        m_list = range(2, 5)\n",
    "    elif weather == 'summer':\n",
    "        m_list = range(5, 8)\n",
    "    elif weather == 'fall':\n",
    "        m_list = range(8, 11)\n",
    "    elif weather == 'winter':\n",
    "        m_list = [range(11, 13)] + [1] \n",
    "    \n",
    "    df['fog'] = surface['fog'].replace(fog_split)\n",
    "    df = pd.get_dummies(df, columns = ['fog'])\n",
    "    \n",
    "    # 여름, 가을 계절 : 적설량 변수 제거\n",
    "    if weather in ['summer', 'fall']:\n",
    "        snow_cols = [x for x in df.columns if x.endswith('snow')]\n",
    "        df.drop(snow_cols, axis = 1, inplace = True)\n",
    "    \n",
    "    # 계절별 데이터 출력\n",
    "    df = df[df['month'].isin(m_list)].reset_index(drop = True)\n",
    "    \n",
    "    # day -> week, month_week 범주화\n",
    "    df['new_day'] = df['day'].apply(lambda x: 1 if x in range(1,8) else (2 if x in range(8,15) else (3 if x in range(15,22) else 4)))\n",
    "    df['MMDD'] = df['month'].astype('int').astype('str') + '_' + df['new_day'].astype('int').astype('str').str.zfill(2)\n",
    "    df = pd.get_dummies(df, columns = ['MMDD'])\n",
    "    df.drop(['new_day'], axis=1, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d838ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중평균 특성변수 생성\n",
    "def create_weighted_average_feature(data, variables, lags):\n",
    "    for variable in variables:\n",
    "        for lag in lags:\n",
    "            data[f'{variable}_lag{lag}'] = data[variable].shift(lag)\n",
    "    for variable in variables:\n",
    "        weights = [1 / lag for lag in lags]\n",
    "        weighted_average = np.average(data[[f'{variable}_lag{lag}' for lag in lags]], axis=1, weights=weights)\n",
    "        data[f'{variable}_weighted_avg'] = weighted_average\n",
    "    data.drop([f'{variable}_lag{lag}' for variable in variables for lag in lags], axis=1, inplace=True)\n",
    "    return data.dropna()\n",
    "\n",
    "# create_weighted_average_feature함수를 이용해 가중평균합 변수 생성 & train/val set으로 분리\n",
    "def gen_train_val(original_df):\n",
    "    df = original_df.copy()\n",
    "\n",
    "    # train / val dataframe 생성\n",
    "    train = df[(df.year<='D') & (df.area.isin([1,2,3,4,5,6,7]))].reset_index(drop=True)\n",
    "    val = df[(df.year=='E') & (df.area.isin([8,9,10]))].reset_index(drop=True)\n",
    "\n",
    "    # 가중평균 해줄 변수\n",
    "    variables = ['temp', 'dp_temp', 'rain', 'solar_amt', 'snow']\n",
    "    lags = [1,2,3]\n",
    "        \n",
    "    # weighted average feature : area별로 생성\n",
    "    df_train = pd.DataFrame()\n",
    "    for i in np.unique(train.area).tolist():\n",
    "        temp = train[train.area==i]        \n",
    "        temp_ = create_weighted_average_feature(temp, variables, lags)\n",
    "        df_train = pd.concat([df_train, temp_], axis=0)\n",
    "\n",
    "    df_val = pd.DataFrame()\n",
    "    for i in np.unique(val.area).tolist():\n",
    "        temp = val[val.area==i]\n",
    "        temp_ = create_weighted_average_feature(temp, variables, lags)\n",
    "        df_val = pd.concat([df_val, temp_], axis=0)\n",
    "\n",
    "    return df_train, df_val\n",
    "\n",
    "# create_weighted_average_feature함수를 이용해 가중평균합 변수 생성 & train/val set으로 분리\n",
    "# 여기서 train set = train + val\n",
    "def gen_train_test(original_df):\n",
    "    df = original_df.copy()\n",
    "\n",
    "    # train / test dataframe 생성\n",
    "    train = df[df.year<='E'].reset_index(drop=True)\n",
    "    test = df[df.year=='F'].reset_index(drop=True)\n",
    "\n",
    "    # weighted average feature area별로 생성\n",
    "    df_train = pd.DataFrame()\n",
    "    for i in np.unique(train.area).tolist():\n",
    "        temp = train[train.area==i]\n",
    "        variables = ['temp', 'dp_temp', 'rain', 'solar_amt', 'snow']\n",
    "        lags = [1,2,3]\n",
    "        temp_ = create_weighted_average_feature(temp, variables, lags)\n",
    "        df_train = pd.concat([df_train, temp_], axis=0)\n",
    "\n",
    "    df_test = pd.DataFrame()\n",
    "    for i in np.unique(test.area).tolist():\n",
    "        temp = test[test.area==i]\n",
    "        temp_ = create_weighted_average_feature(temp, variables, lags)\n",
    "        df_test = pd.concat([df_test, temp_], axis=0)\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0aebaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역별 10개의 catboost 모델 튜닝 (Gaussian Process 이용) 후 ensemble 모형 생성\n",
    "def gen_ensemble_model(train_df):\n",
    "    \n",
    "    # feature/target 분리\n",
    "    X_tv = train_df.drop(['month','day','hour','land_temp'], axis = 1).reset_index(drop=True)\n",
    "    y_tv = train_df[['area','land_temp']].reset_index(drop=True)\n",
    "    \n",
    "    # train area 별로 분리 (1 - 10)\n",
    "    for i in range(1, 11):\n",
    "        globals()['X_tv'+str(i)] = X_tv[X_tv['area'] == i].reset_index(drop=True).drop(['area'], axis=1)\n",
    "        globals()['y_tv'+str(i)] = y_tv.loc[y_tv['area'] == i, 'land_temp'].reset_index(drop=True)\n",
    "        \n",
    "    # area 별로 catboost model tuning 후 저장\n",
    "    for i in range(1, 11):\n",
    "        print('area', i)\n",
    "        space = [\n",
    "            Integer(1,10, name='depth'),\n",
    "            Real(0.01,0.3, 'uniform', name='learning_rate'),\n",
    "            Integer(2,30,name='l2_leaf_reg'),\n",
    "            Integer(100,500,name='iterations')\n",
    "        ]\n",
    "        groups = globals()['X_tv'+str(i)].year.reset_index(drop=True).values\n",
    "        globals()['X_tv'+str(i)].drop(['year'], axis=1, inplace=True)\n",
    "        \n",
    "        @use_named_args(space)\n",
    "        def objective(**params):\n",
    "            model = CatBoostRegressor(random_seed=0, verbose = False)\n",
    "            model.set_params(**params)\n",
    "\n",
    "            gscv = GroupTimeSeriesSplit(n_splits=4)\n",
    "            mae = []\n",
    "            \n",
    "            for train_index, valid_index in gscv.split(globals()['X_tv'+str(i)], groups=groups):\n",
    "                X_train, X_valid = globals()['X_tv'+str(i)].loc[train_index], globals()['X_tv'+str(i)].loc[valid_index]\n",
    "                y_train, y_valid = globals()['y_tv'+str(i)].loc[train_index], globals()['y_tv'+str(i)].loc[valid_index]\n",
    "\n",
    "                model.fit(X_train, y_train, verbose=False)\n",
    "                y_pred = model.predict(X_valid)\n",
    "                mae.append(mean_absolute_error(y_valid, y_pred))\n",
    "                \n",
    "            return np.mean(mae)\n",
    "        \n",
    "        best = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "        \n",
    "        best_params = {\n",
    "            'depth': best.x[0],\n",
    "            'learning_rate': best.x[1],\n",
    "            'l2_leaf_reg': best.x[2],\n",
    "            'iterations': best.x[3]\n",
    "        }\n",
    "        \n",
    "        model = CatBoostRegressor(random_seed=0, verbose = False)\n",
    "        model.set_params(**best_params)\n",
    "        globals()['model_cat'+str(i)] = model\n",
    "        \n",
    "    catboost_models = []\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        catboost_models.append(('catboost_'+str(i), globals()['model_cat'+str(i)]))\n",
    "        \n",
    "    ensemble_model = VotingRegressor(estimators = catboost_models)\n",
    "    \n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "265986bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_excel('./subminssionUser.xlsx', sheet_name=None)['SPRING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8042533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = 'C:/Users/dongk/Data_Handling/공모전/날씨 빅데이터 콘테스트/datasets/'\n",
    "surface_train = pd.read_csv(path+'train0624.csv')\n",
    "surface_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "surface_test = pd.read_csv(path+'imputed_test_data0624.csv')\n",
    "surface_test.insert(11, column='land_temp', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f722f5d",
   "metadata": {},
   "source": [
    "area 1,2,3 : 3월 23일 14시 결측치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb5124",
   "metadata": {},
   "source": [
    "## train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01e29ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_train_fe = gen_feature(surface_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10068cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'temp', 'dp_temp', 'humid' 3개 변수에 대해 1, 2, 12, 24 lag 변수와 해당 lag의 percentage change 추가 + 기타 lag 변수들과 interaction들 추가\n",
    "surface_train_lag = add_lag(original_df = surface_train_fe, \n",
    "                            lag_cols = ['temp', 'dp_temp', 'humid'], #lag 추가하는 변수들 \n",
    "                            lags = [1,2,12,24],\n",
    "                            t = 'train') #추가 lag들\n",
    "#spring: 맑음 / 눈&비 / 기타 구분 & snow에 대한 adjustment \n",
    "f = {x:3 for x in np.unique(surface_train.fog)}\n",
    "f.update({'C':1, 'R':2, 'S':2})\n",
    "spring_train = make_weather_df(original_df = surface_train_lag,\n",
    "                               surface = surface_train,\n",
    "                               weather = 'spring',\n",
    "                               adj = True, #snow adjustment 여부\n",
    "                               fog_split = f)\n",
    "\n",
    "spring_train = spring_train.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bd70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4805748",
   "metadata": {},
   "source": [
    "## Val set 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a040fd-4bc8-4a1a-b12d-89da6612d0b7",
   "metadata": {},
   "source": [
    "- train set의 area와 test set의 area가 상이한 특징 \n",
    "- 이러한 test set의 특성을 반영하기 위해 train set : A,B,C,D년도 & 1,2,3,4,5,6,7 area 로 구성하였고 val set : E년도 & 8,9,10 area로 구성하여 검증을 진행하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d660e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = gen_train_val(spring_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a551efbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: [1.4346 1.5813 1.4805]\n",
      "total mae: 1.4988\n"
     ]
    }
   ],
   "source": [
    "groups = train_df.year.reset_index(drop=True).values\n",
    "X_train = train_df.drop(['year','land_temp','day','area','hour','month'], axis=1).reset_index(drop=True)\n",
    "y_train = train_df['land_temp'].reset_index(drop=True)\n",
    "\n",
    "X_val = val_df.drop(['year','land_temp','day','area','hour','month'], axis=1).reset_index(drop=True)\n",
    "y_val = val_df['land_temp'].reset_index(drop=True)\n",
    "\n",
    "model = CatBoostRegressor(silent = True, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "mae_ls = list()\n",
    "for i in np.unique(val_df.area).tolist():\n",
    "    globals()[f'X_val_{i}'] = val_df[val_df.area == i].drop(['year','land_temp','day','area','hour','month'], axis=1).reset_index(drop=True)\n",
    "    globals()[f'y_val_{i}'] = val_df[val_df.area == i]['land_temp'].reset_index(drop=True)\n",
    "\n",
    "    globals()[f'y_pred_{i}'] = model.predict(globals()[f'X_val_{i}'])\n",
    "    mae = mean_absolute_error(globals()[f'y_val_{i}'], globals()[f'y_pred_{i}'])\n",
    "    mae_ls.append(mae)\n",
    "\n",
    "print(f'mae: {np.round(mae_ls, 4)}')\n",
    "print(f'total mae: {np.mean(mae_ls):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a7ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54dac501",
   "metadata": {
    "tags": []
   },
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95f85918",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_test_fe = gen_feature(surface_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "124c11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'temp', 'dp_temp', 'humid' 3개 변수에 대해 1, 2, 12, 24 lag 변수와 해당 lag의 percentage change 추가 + 기타 lag 변수들과 interaction들 추가\n",
    "surface_test_lag = add_lag(original_df = surface_test_fe, \n",
    "                      lag_cols = ['temp', 'dp_temp', 'humid'], #lag 추가하는 변수들 \n",
    "                      lags = [1, 2, 12, 24],\n",
    "                      t = 'test') #추가 lag들 \n",
    "#spring: 맑음 / 눈&비 / 기타 구분 & snow에 대한 adjustment \n",
    "f = {x:3 for x in np.unique(surface_test.fog)}\n",
    "f.update({'C':1, 'R':2, 'S':2})\n",
    "spring_test = make_weather_df(original_df = surface_test_lag,\n",
    "                              surface = surface_test,\n",
    "                              weather = 'spring',\n",
    "                              adj = True, #snow adjustment 여부 \n",
    "                              fog_split = f)\n",
    "\n",
    "spring_test = spring_test.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train shape: {spring_train.shape}')\n",
    "print(f'test shape: {spring_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97763ff9-f11e-4982-9471-3c3430c6014f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04edbedf",
   "metadata": {},
   "source": [
    "- 전체 데이터를 학습 시키는데 사용할 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "214a4dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp_temp</th>\n",
       "      <th>humid</th>\n",
       "      <th>area</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>MMDD_2_03</th>\n",
       "      <th>MMDD_2_04</th>\n",
       "      <th>MMDD_3_01</th>\n",
       "      <th>MMDD_3_02</th>\n",
       "      <th>MMDD_3_03</th>\n",
       "      <th>MMDD_3_04</th>\n",
       "      <th>MMDD_4_01</th>\n",
       "      <th>MMDD_4_02</th>\n",
       "      <th>MMDD_4_03</th>\n",
       "      <th>MMDD_4_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.130176</td>\n",
       "      <td>0.721790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.184849</td>\n",
       "      <td>0.733955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.239775</td>\n",
       "      <td>0.740426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dp_temp     humid  area year  month  day  hour  temp  wind  rain  ...  \\\n",
       "0 -11.130176  0.721790   1.0    A    2.0  2.0   0.0  -9.0   0.8   0.0  ...   \n",
       "1 -11.184849  0.733955   1.0    A    2.0  2.0   1.0  -9.9   0.7   0.0  ...   \n",
       "2 -11.239775  0.740426   1.0    A    2.0  2.0   2.0 -10.7   0.7   0.0  ...   \n",
       "\n",
       "   MMDD_2_03  MMDD_2_04  MMDD_3_01  MMDD_3_02  MMDD_3_03  MMDD_3_04  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "\n",
       "   MMDD_4_01  MMDD_4_02  MMDD_4_03  MMDD_4_04  \n",
       "0          0          0          0          0  \n",
       "1          0          0          0          0  \n",
       "2          0          0          0          0  \n",
       "\n",
       "[3 rows x 52 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spring = pd.concat([spring_train, spring_test], axis=0).reset_index(drop=True)\n",
    "spring.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d052e2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp_temp</th>\n",
       "      <th>humid</th>\n",
       "      <th>area</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>MMDD_2_03</th>\n",
       "      <th>MMDD_2_04</th>\n",
       "      <th>MMDD_3_01</th>\n",
       "      <th>MMDD_3_02</th>\n",
       "      <th>MMDD_3_03</th>\n",
       "      <th>MMDD_3_04</th>\n",
       "      <th>MMDD_4_01</th>\n",
       "      <th>MMDD_4_02</th>\n",
       "      <th>MMDD_4_03</th>\n",
       "      <th>MMDD_4_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dp_temp, humid, area, year, month, day, hour, temp, wind, rain, tf_rain, land_temp, solar_amt, solar_time, snow, hour_sin, hour_cos, temp_diff, temp_lag_1, temp_lag_2, temp_lag_12, temp_lag_24, dp_temp_lag_1, dp_temp_lag_2, dp_temp_lag_12, dp_temp_lag_24, humid_lag_1, humid_lag_2, humid_lag_12, humid_lag_24, rain_count, solar_amt_sum, after_snow, after_rain, temp_dp_temp, temp_humid, temp_wind, fog_1, fog_2, fog_3, MMDD_2_01, MMDD_2_02, MMDD_2_03, MMDD_2_04, MMDD_3_01, MMDD_3_02, MMDD_3_03, MMDD_3_04, MMDD_4_01, MMDD_4_02, MMDD_4_03, MMDD_4_04]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 52 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spring[spring.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cb58f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (105952, 57)\n",
      "test: (6327, 57)\n"
     ]
    }
   ],
   "source": [
    "# # create weighted average feature\n",
    "train_df, test_df = gen_train_test(spring)\n",
    "print(f'train: {train_df.shape}')\n",
    "print(f'test: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "694a97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['MMDDHH'] = test_df['month'].astype('int').astype('str') + test_df['day'].astype('int').astype('str').str.zfill(2) + test_df['hour'].astype('int').astype('str').str.zfill(2)\n",
    "test_df['MMDDHH'] = test_df['MMDDHH'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a907d88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp_temp</th>\n",
       "      <th>humid</th>\n",
       "      <th>area</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>MMDD_3_04</th>\n",
       "      <th>MMDD_4_01</th>\n",
       "      <th>MMDD_4_02</th>\n",
       "      <th>MMDD_4_03</th>\n",
       "      <th>MMDD_4_04</th>\n",
       "      <th>temp_weighted_avg</th>\n",
       "      <th>dp_temp_weighted_avg</th>\n",
       "      <th>rain_weighted_avg</th>\n",
       "      <th>solar_amt_weighted_avg</th>\n",
       "      <th>snow_weighted_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMDDHH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20203</th>\n",
       "      <td>-10.232145</td>\n",
       "      <td>0.563850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.945455</td>\n",
       "      <td>-10.224309</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20204</th>\n",
       "      <td>-10.236587</td>\n",
       "      <td>0.563445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.236364</td>\n",
       "      <td>-10.229201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20205</th>\n",
       "      <td>-10.241075</td>\n",
       "      <td>0.563039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.527273</td>\n",
       "      <td>-10.233768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dp_temp     humid  area year  month  day  hour  temp  wind  rain  \\\n",
       "MMDDHH                                                                       \n",
       "20203  -10.232145  0.563850   1.0    F    2.0  2.0   3.0  -4.4   2.3   0.0   \n",
       "20204  -10.236587  0.563445   1.0    F    2.0  2.0   4.0  -4.7   1.4   0.0   \n",
       "20205  -10.241075  0.563039   1.0    F    2.0  2.0   5.0  -4.8   1.3   0.0   \n",
       "\n",
       "        ...  MMDD_3_04  MMDD_4_01  MMDD_4_02  MMDD_4_03  MMDD_4_04  \\\n",
       "MMDDHH  ...                                                          \n",
       "20203   ...          0          0          0          0          0   \n",
       "20204   ...          0          0          0          0          0   \n",
       "20205   ...          0          0          0          0          0   \n",
       "\n",
       "        temp_weighted_avg  dp_temp_weighted_avg  rain_weighted_avg  \\\n",
       "MMDDHH                                                               \n",
       "20203           -3.945455            -10.224309           0.017304   \n",
       "20204           -4.236364            -10.229201           0.000000   \n",
       "20205           -4.527273            -10.233768           0.000000   \n",
       "\n",
       "        solar_amt_weighted_avg  snow_weighted_avg  \n",
       "MMDDHH                                             \n",
       "20203                      0.0                0.0  \n",
       "20204                      0.0                0.0  \n",
       "20205                      0.0                0.0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.set_index('MMDDHH')\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40f6d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6327, 57)\n"
     ]
    }
   ],
   "source": [
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5600a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6975d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32783880",
   "metadata": {},
   "source": [
    "## 검증데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b688176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area 1\n",
      "area 2\n",
      "area 3\n",
      "area 4\n",
      "area 5\n",
      "area 6\n",
      "area 7\n",
      "area 8\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = gen_ensemble_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature/target 분리\n",
    "X_tv = train_df.drop(['land_temp','hour','day','month'], axis = 1).reset_index(drop=True)\n",
    "y_tv = train_df[['area', 'land_temp']].reset_index(drop=True)\n",
    "\n",
    "# train area 별로 분리 (1 - 10)\n",
    "for i in range(1, 11):\n",
    "    globals()['X_tv'+str(i)] = X_tv[X_tv['area'] == i].reset_index(drop=True).drop(['area','year'], axis=1)\n",
    "    globals()['y_tv'+str(i)] = y_tv.loc[y_tv['area'] == i, 'land_temp'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4694ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ensemble model\n",
    "ensemble_X_tv = pd.DataFrame()\n",
    "ensemble_y_tv = pd.DataFrame()\n",
    "\n",
    "for i in range(1,11):\n",
    "    ensemble_X_tv = pd.concat([ensemble_X_tv, globals()['X_tv'+str(i)]], axis=0)\n",
    "    ensemble_y_tv = pd.concat([ensemble_y_tv, globals()['y_tv'+str(i)]], axis=0)\n",
    "\n",
    "ensemble_model.fit(ensemble_X_tv, ensemble_y_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4097d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_df.area.unique():\n",
    "    globals()[f'X_test_{i}'] = test_df[test_df.area==i].drop(['land_temp','hour','day','year','area','month'], axis=1)\n",
    "    globals()[f'y_pred_{i}'] = ensemble_model.predict(globals()[f'X_test_{i}'])\n",
    "    \n",
    "    globals()[f'y_pred_{int(i)}'] = pd.Series(globals()[f'y_pred_{i}'], index = globals()[f'X_test_{i}'].index, name='pred')\n",
    "    globals()[f'y_pred_{int(i)}'] = pd.DataFrame(globals()[f'y_pred_{int(i)}'])\n",
    "    globals()[f'y_pred_{int(i)}'].reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b992e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "for i in range(1,4):\n",
    "    area = dat.STN.unique().tolist()\n",
    "    temp = dat[dat.STN==area[i-1]]\n",
    "    temp_ = pd.merge(temp,globals()[f'y_pred_{int(i)}'], on='MMDDHH', how='left')\n",
    "    pred_df = pd.concat([pred_df, temp_], axis=0)\n",
    "    \n",
    "pred_df.drop(['TS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[pred_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb103ce-243e-42d0-ac12-44ce4b38ed71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2311d07-8fa2-49c8-93b5-5e92ea6f45aa",
   "metadata": {},
   "source": [
    "## Spring NA 값 예측 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5bb96",
   "metadata": {},
   "source": [
    "- lag feature로 인해 생기는 nan 값을 예측하기 위해, shifting 시켜주지 않고 데이터 구성\n",
    "- nan 값이 많지 않아 전체 모델링에 큰 영향을 미치지 않을 것이라 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72460a-d417-4412-af06-f11dfd5a1640",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea1209f3-557b-49ac-9714-30fb0006b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_train_fe = gen_feature(surface_train)\n",
    "\n",
    "surface_train_wv = gen_wv_df(surface_train_fe, t: 'train')\n",
    "\n",
    "#spring: 맑음 / 눈&비 / 기타 구분 & snow에 대한 adjustment \n",
    "f = {x:3 for x in np.unique(surface_train.fog)}\n",
    "f.update({'C':1, 'R':2, 'S':2})\n",
    "spring_train = make_weather_df(original_df = surface_train_wv,\n",
    "                               surface = surface_train,\n",
    "                               weather = 'spring',\n",
    "                               adj = True, #snow adjustment 하는지 \n",
    "                               fog_split = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc0a9b-8a8e-40e6-974f-d027a8530a2c",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c20af1c7-0b91-4828-810b-af202001e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_test_fe = gen_feature(surface_test)\n",
    "\n",
    "surface_test_wv = gen_wv_df(surface_test_fe, t: 'test')\n",
    "\n",
    "#spring: 맑음 / 눈&비 / 기타 구분 & snow에 대한 adjustment \n",
    "f = {x:3 for x in np.unique(surface_test.fog)}\n",
    "f.update({'C':1, 'R':2, 'S':2})\n",
    "spring_test = make_weather_df(original_df = surface_test_wv,\n",
    "                              surface = surface_test,\n",
    "                              weather = 'spring',\n",
    "                              adj = True, #snow adjustment 하는지 \n",
    "                              fog_split = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb7d69-693f-4d25-91e5-b8a40041853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6408, 33)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape: {spring_train.shape}')\n",
    "print(f'test shape: {spring_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "376bc8ed-b6b5-4bad-8f45-1c55b3bf54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = spring_train.copy(), spring_test.copy()\n",
    "\n",
    "test_df['MMDDHH'] = test_df['month'].astype('int').astype('str') + test_df['day'].astype('int').astype('str').str.zfill(2) + test_df['hour'].astype('int').astype('str').str.zfill(2)\n",
    "test_df['MMDDHH'] = test_df['MMDDHH'].astype('int64')\n",
    "\n",
    "test_df = test_df.set_index('MMDDHH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d895a85-9b79-4f53-ab45-4d4193f10dec",
   "metadata": {},
   "source": [
    "### na 모델 생성 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b952c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area 1\n",
      "area 2\n",
      "area 3\n",
      "area 4\n",
      "area 5\n",
      "area 6\n",
      "area 7\n",
      "area 8\n",
      "area 9\n",
      "area 10\n"
     ]
    }
   ],
   "source": [
    "ensemble_na_model = gen_ensemble_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "913abe95-9e45-434d-91e9-8f82897e051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature/target 분리\n",
    "X_tv = train_df.drop(['land_temp','hour','day','month'], axis = 1).reset_index(drop=True)\n",
    "y_tv = train_df[['area', 'land_temp']].reset_index(drop=True)\n",
    "\n",
    "# train area 별로 분리 (1 - 10)\n",
    "for i in range(1, 11):\n",
    "    globals()['X_tv'+str(i)] = X_tv[X_tv['area'] == i].reset_index(drop=True).drop(['area','year'], axis=1)\n",
    "    globals()['y_tv'+str(i)] = y_tv.loc[y_tv['area'] == i, 'land_temp'].reset_index(drop=True)\n",
    "\n",
    "# Fit the ensemble model\n",
    "ensemble_X_tv = pd.DataFrame()\n",
    "ensemble_y_tv = pd.DataFrame()\n",
    "\n",
    "for i in range(1,11):\n",
    "    ensemble_X_tv = pd.concat([ensemble_X_tv, globals()['X_tv'+str(i)]], axis=0)\n",
    "    ensemble_y_tv = pd.concat([ensemble_y_tv, globals()['y_tv'+str(i)]], axis=0)\n",
    "\n",
    "ensemble_na_model.fit(ensemble_X_tv, ensemble_y_tv)\n",
    "\n",
    "for i in test_df.area.unique():\n",
    "    globals()[f'X_test_{i}'] = test_df[test_df.area==i].drop(['land_temp','hour','day','year','area','month'], axis=1)\n",
    "    globals()[f'y_pred_{i}'] = ensemble_na_model.predict(globals()[f'X_test_{i}'])\n",
    "    \n",
    "    globals()[f'y_pred_{int(i)}'] = pd.Series(globals()[f'y_pred_{i}'], index = globals()[f'X_test_{i}'].index, name='pred')\n",
    "    globals()[f'y_pred_{int(i)}'] = pd.DataFrame(globals()[f'y_pred_{int(i)}'])\n",
    "    globals()[f'y_pred_{int(i)}'].reset_index(inplace=True)\n",
    "    \n",
    "pred_nona = pd.DataFrame()\n",
    "for i in range(1,4):\n",
    "    area = dat.STN.unique().tolist()\n",
    "    temp = dat[dat.STN==area[i-1]]\n",
    "    temp_ = pd.merge(temp,globals()[f'y_pred_{int(i)}'], on='MMDDHH', how='left')\n",
    "    pred_nona = pd.concat([pred_nona, temp_], axis=0)\n",
    "    \n",
    "pred_nona.drop(['TS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "623baee7-7a58-4066-826f-147e5f2eaecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STN</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MMDDHH</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [STN, YEAR, MMDDHH, pred]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nona[pred_nona.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "320af714-5807-4d85-a333-af4c7a90f4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6405, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nona.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag변수로 인해 생기는 결측치 대체\n",
    "idx = pred_df[pred_df.isna().any(axis=1)].index\n",
    "pred_df.loc[idx,'pred'] = pred_nona.loc[idx,'pred']\n",
    "pred_df[pred_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9b812cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('제출 df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d8b06-c4e8-4ad2-b27a-faa4ed01f875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
